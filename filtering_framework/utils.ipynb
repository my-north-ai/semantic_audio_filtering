{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cv_16_train = load_dataset(\"mozilla-foundation/common_voice_16_1\", \"pt\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_16_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data'\n",
    "wav_folder = os.path.join(data_folder, 'wav_data')\n",
    "manifest_folder = os.path.join(data_folder, 'manifest_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hf_dataset_to_wav(dataset, dataset_type, manifest_filename):\n",
    "\n",
    "    manifest_filepath = os.path.join(manifest_folder, manifest_filename)\n",
    "\n",
    "    with open(manifest_filepath, 'w') as manifest_f:\n",
    "        for sample in tqdm(dataset, desc=\"Converting HF Dataset to Manifest: \"):\n",
    "            if dataset_type == 'mls':\n",
    "                text_column = 'text'\n",
    "            elif dataset_type == 'common_voice':\n",
    "                text_column = 'sentence'\n",
    "            elif dataset_type == 'customized':\n",
    "                text_column = 'text'\n",
    "            else:\n",
    "                raise ValueError(\"Dataset type not supported\")\n",
    "\n",
    "            transcription = sample[text_column]\n",
    "            audio = sample['audio']\n",
    "            audio_name = os.path.splitext(os.path.basename(audio['path']))[0]\n",
    "            wav_file_path = os.path.join(wav_folder, audio_name + '.wav')\n",
    "\n",
    "            if not os.path.exists(wav_file_path):\n",
    "                try:\n",
    "                    # Resample to 16kHz\n",
    "                    audio_resampled = librosa.resample(y=audio['array'], orig_sr=audio['sampling_rate'], target_sr=16000)\n",
    "                    sf.write(wav_file_path, audio_resampled, samplerate=16000)\n",
    "                    duration = librosa.get_duration(y=audio_resampled, sr=16000)\n",
    "                except sf.LibsndfileError as e:\n",
    "                    print(\"Error:\", e, \"with audio:\", audio_name)\n",
    "                    continue\n",
    "            else:\n",
    "                duration = librosa.get_duration(filename=wav_file_path)\n",
    "\n",
    "            manifest_line = {\n",
    "                'audio_filepath': wav_file_path,\n",
    "                'text': transcription,\n",
    "                'duration': duration,\n",
    "            }\n",
    "\n",
    "            json.dump(manifest_line, manifest_f, ensure_ascii=False)\n",
    "            manifest_f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting HF Dataset to Manifest:   0%|          | 0/21685 [00:00<?, ?it/s]/var/folders/mp/1mlhtgp14_x4hhcdlgr2xhy40000gp/T/ipykernel_3689/4119253124.py:31: FutureWarning: get_duration() keyword argument 'filename' has been renamed to 'path' in version 0.10.0.\n",
      "\tThis alias will be removed in version 1.0.\n",
      "  duration = librosa.get_duration(filename=wav_file_path)\n",
      "Converting HF Dataset to Manifest:  16%|█▌        | 3519/21685 [00:15<01:22, 220.43it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconvert_hf_dataset_to_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv_16_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcommon_voice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmanifest_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcommon_voice_16_1_train_manifest.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 24\u001b[0m, in \u001b[0;36mconvert_hf_dataset_to_wav\u001b[0;34m(dataset, dataset_type, manifest_filename)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(wav_file_path):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;66;03m# Resample to 16kHz\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m         audio_resampled \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maudio\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marray\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_sr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maudio\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msampling_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_sr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m         sf\u001b[38;5;241m.\u001b[39mwrite(wav_file_path, audio_resampled, samplerate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m)\n\u001b[1;32m     26\u001b[0m         duration \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mget_duration(y\u001b[38;5;241m=\u001b[39maudio_resampled, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/tts-data-augmentation-vGKV77-n-py3.11/lib/python3.11/site-packages/librosa/core/audio.py:669\u001b[0m, in \u001b[0;36mresample\u001b[0;34m(y, orig_sr, target_sr, res_type, fix, scale, axis, **kwargs)\u001b[0m\n\u001b[1;32m    663\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mapply_along_axis(\n\u001b[1;32m    664\u001b[0m         samplerate\u001b[38;5;241m.\u001b[39mresample, axis\u001b[38;5;241m=\u001b[39maxis, arr\u001b[38;5;241m=\u001b[39my, ratio\u001b[38;5;241m=\u001b[39mratio, converter_type\u001b[38;5;241m=\u001b[39mres_type\n\u001b[1;32m    665\u001b[0m     )\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoxr\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;66;03m# Use numpy to vectorize the resampler along the target axis\u001b[39;00m\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;66;03m# This is because soxr does not support ndim>2 generally.\u001b[39;00m\n\u001b[0;32m--> 669\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_along_axis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43msoxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43min_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morig_sr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_sr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    678\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m resampy\u001b[38;5;241m.\u001b[39mresample(y, orig_sr, target_sr, \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39mres_type, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/tts-data-augmentation-vGKV77-n-py3.11/lib/python3.11/site-packages/numpy/lib/shape_base.py:379\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    377\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot apply_along_axis when any iteration dimensions are 0\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    378\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 379\u001b[0m res \u001b[38;5;241m=\u001b[39m asanyarray(\u001b[43mfunc1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43minarr_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind0\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# build a buffer for storing evaluations of func1d.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# remove the requested axis, and add the new ones on the end.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# laid out so that each write is contiguous.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;66;03m# for a tuple index inds, buff[inds] = func1d(inarr_view[inds])\u001b[39;00m\n\u001b[1;32m    385\u001b[0m buff \u001b[38;5;241m=\u001b[39m zeros(inarr_view\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m res\u001b[38;5;241m.\u001b[39mshape, res\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/tts-data-augmentation-vGKV77-n-py3.11/lib/python3.11/site-packages/soxr/__init__.py:159\u001b[0m, in \u001b[0;36mresample\u001b[0;34m(x, in_rate, out_rate, quality)\u001b[0m\n\u001b[1;32m    156\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(x)    \u001b[38;5;66;03m# make array C-contiguous\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 159\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcysoxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcysoxr_divide_proc\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msqueeze(y, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "convert_hf_dataset_to_wav(dataset=cv_16_train, dataset_type='common_voice', manifest_filename='common_voice_16_1_train_manifest.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_id': 'be4164b2664c4d9cdf7d10cf624dfc0e4eb06c2284eb1448bb32273f1513af423e500234654641384a19e5c04c2edfbcd0a1b3fbcc9e296b5ffd79856efce5ca',\n",
       " 'path': '/Users/tmsantos/.cache/huggingface/datasets/downloads/extracted/012e9243ba77a77e48628f0af282362b49a8d918325a3f1f8c5786507fed6b95/pt_train_0/common_voice_pt_25163425.mp3',\n",
       " 'audio': {'path': '/Users/tmsantos/.cache/huggingface/datasets/downloads/extracted/012e9243ba77a77e48628f0af282362b49a8d918325a3f1f8c5786507fed6b95/pt_train_0/common_voice_pt_25163425.mp3',\n",
       "  'array': array([ 4.83169060e-13, -2.27373675e-13, -3.41060513e-13, ...,\n",
       "          9.39775055e-06,  6.62311663e-07, -1.66810230e-06]),\n",
       "  'sampling_rate': 48000},\n",
       " 'sentence': 'Vitória de Santo Antão',\n",
       " 'up_votes': 2,\n",
       " 'down_votes': 0,\n",
       " 'age': '',\n",
       " 'gender': '',\n",
       " 'accent': '',\n",
       " 'locale': 'pt',\n",
       " 'segment': '',\n",
       " 'variant': ''}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def process_sample(sample):\n",
    "    audio = sample['audio']\n",
    "    audio_name = audio['path'].split('/')[-1].split('.')[0]\n",
    "    if not os.path.exists(audio_name):\n",
    "        try:\n",
    "            audio_resampled = librosa.resample(y=audio['array'], orig_sr=audio['sampling_rate'], target_sr=16000)\n",
    "            sf.write('/quartznet_train/'+audio_name+'.wav', audio_resampled, samplerate=16000)\n",
    "        except sf.LibsndfileError as e:\n",
    "            print(audio_name)\n",
    "\n",
    "\n",
    "# Initialize tqdm with the total number of samples\n",
    "progress_bar = tqdm(total=len(dataset_train), desc=\"Processing samples\")\n",
    "\n",
    "# Process each sample in the dataset\n",
    "for sample in dataset_train:\n",
    "    process_sample(sample)\n",
    "    progress_bar.update(1)\n",
    "\n",
    "# Close the progress bar after finishing the loop\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tts-data-augmentation-vGKV77-n-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
